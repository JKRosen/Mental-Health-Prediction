{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d  = pd.read_csv(\"new_DF_withreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source  label  illness\n",
       "m       1      ptsd         24\n",
       "        2      ocd         322\n",
       "        3      anx        1865\n",
       "        4      bd         2333\n",
       "        5      dep        3135\n",
       "r       1      ptsd        420\n",
       "        2      ocd         736\n",
       "        3      anx        1251\n",
       "        4      bd         2832\n",
       "        5      dep         471\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.groupby([\"source\",\"label\",'illness']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1     444\n",
       "2    1058\n",
       "3    3116\n",
       "4    5165\n",
       "5    3606\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.groupby([\"label\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'postID', 'illness', 'label', 'wpp', 'Ipp', 'PRON', 'AUX',\n",
       "       'VERB', 'ADP', 'CCONJ', 'NOUN', 'ADJ', 'DET', 'ADV', 'PART', 'SCONJ',\n",
       "       'PROPN', 'NUM', 'INTJ', 'X', 'PUNCT', 'SYM', 'compound', 'neg', 'neu',\n",
       "       'pos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scramble\n",
    "d = d.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1020\n",
       "2    1058\n",
       "3    3116\n",
       "4    5165\n",
       "5    3606\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upsample class 1\n",
    "d_minority = d[d.label==1]\n",
    "d_minority_upsampled = resample(d_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=576,    # to match majority class\n",
    "                                 random_state=123)\n",
    "\n",
    "d = pd.concat([d, d_minority_upsampled])\n",
    "d.groupby([\"label\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1020\n",
       "2    1634\n",
       "3    3116\n",
       "4    5165\n",
       "5    3606\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upsample class 2\n",
    "d_minority = d[d.label==2]\n",
    "d_minority_upsampled = resample(d_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=576,    # to match majority class\n",
    "                                 random_state=123)\n",
    "\n",
    "d = pd.concat([d, d_minority_upsampled])\n",
    "d.groupby([\"label\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# down and up sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1500\n",
       "2    1500\n",
       "3    1500\n",
       "4    1500\n",
       "5    1500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "dfdict = defaultdict()\n",
    "for i in range(1,6):\n",
    "    d_minority = d[d.label==i]\n",
    "    d_minority_upsampled = resample(d_minority, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=1500,    # to match majority class\n",
    "                                     random_state=123)\n",
    "    dfdict[i] =  d_minority_upsampled\n",
    "d = pd.concat([dfdict[1],dfdict[2],dfdict[3],dfdict[4],dfdict[5]])\n",
    "d.groupby([\"label\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidate(classifier,X,T,CV=4):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scores = cross_val_score(classifier, X, T, cv=CV)\n",
    "    print('--- 4-fold cross-validation accuracy: %%%.1f (+/-%.1f)' % (scores.mean()*100,scores.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scramble\n",
    "d = d.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest; 70/30 split; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob Rosen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.95555555555556 %\n"
     ]
    }
   ],
   "source": [
    "d_word0_data = d[d.columns[5:]].as_matrix()\n",
    "\n",
    "features = d_word0_data\n",
    "labels = np.array(d[\"label\"])\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000,random_state=0, n_jobs=-1)\n",
    "rf.fit(train_features, train_labels)\n",
    "predictions = rf.predict(test_features)\n",
    "# predictions\n",
    "errors = []\n",
    "for x,pre in enumerate(predictions):\n",
    "    if pre != test_labels[x]:\n",
    "        errors.append((pre,test_labels[x],x))\n",
    "# print(len(errors))\n",
    "# print(len(test_labels))\n",
    "print(\"Accuracy:\",(len(test_labels) - len(errors))/len(test_labels)*100,\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.79      0.86       555\n",
      "           2       0.75      0.72      0.73       465\n",
      "           3       0.41      0.59      0.48       300\n",
      "           4       0.46      0.62      0.53       331\n",
      "           5       0.73      0.54      0.62       599\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      2250\n",
      "   macro avg       0.66      0.65      0.65      2250\n",
      "weighted avg       0.70      0.66      0.67      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(predictions, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest; 70/30 split; min 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob Rosen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.4927797833935 %\n"
     ]
    }
   ],
   "source": [
    "mask_word20 = (d[\"wpp\"] >= 20)\n",
    "# mask_word20\n",
    "\n",
    "d_word20 = d[mask_word20]\n",
    "\n",
    "#isolate data\n",
    "d_word20_data = d_word20[d.columns[5:]].as_matrix()\n",
    "\n",
    "features = d_word20_data\n",
    "labels = np.array(d_word20[\"label\"])\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000,random_state=0, n_jobs=-1)\n",
    "rf.fit(train_features, train_labels)\n",
    "predictions = rf.predict(test_features)\n",
    "# predictions\n",
    "errors = []\n",
    "for x,pre in enumerate(predictions):\n",
    "    if pre != test_labels[x]:\n",
    "        errors.append((pre,test_labels[x],x))\n",
    "# print(len(errors))\n",
    "# print(len(test_labels))\n",
    "print(\"Accuracy:\",(len(test_labels) - len(errors))/len(test_labels)*100,\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.75      0.83       511\n",
      "           2       0.73      0.75      0.74       452\n",
      "           3       0.35      0.62      0.45       277\n",
      "           4       0.45      0.54      0.50       344\n",
      "           5       0.75      0.52      0.61       632\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      2216\n",
      "   macro avg       0.64      0.64      0.62      2216\n",
      "weighted avg       0.69      0.63      0.65      2216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(predictions, test_labels))\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns; sns.set()\n",
    "# import matplotlib.pyplot as plt\n",
    "# mat = confusion_matrix(test_labels, predictions)\n",
    "# sns.heatmap(mat.T, square = True, annot = True, fmt ='d', cbar = True)\n",
    "# plt.xlabel('true label')\n",
    "# plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest; 70/30 split; min 30 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob Rosen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.4819944598338 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.76      0.85       544\n",
      "           2       0.70      0.73      0.71       411\n",
      "           3       0.47      0.66      0.55       311\n",
      "           4       0.43      0.69      0.53       291\n",
      "           5       0.78      0.53      0.63       609\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      2166\n",
      "   macro avg       0.67      0.67      0.65      2166\n",
      "weighted avg       0.72      0.66      0.68      2166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mask_word30 = (d[\"wpp\"] >= 30)\n",
    "# mask_word20\n",
    "d_word30 = d[mask_word30]\n",
    "d_word30_data = d_word30[d.columns[5:]].as_matrix()\n",
    "\n",
    "features = d_word30_data\n",
    "labels = np.array(d_word30[\"label\"])\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000,random_state=0, n_jobs=-1,class_weight = \"balanced\")\n",
    "rf.fit(train_features, train_labels)\n",
    "predictions = rf.predict(test_features)\n",
    "# predictions\n",
    "errors = []\n",
    "for x,pre in enumerate(predictions):\n",
    "    if pre != test_labels[x]:\n",
    "        errors.append((pre,test_labels[x],x))\n",
    "# print(len(errors))\n",
    "# print(len(test_labels))\n",
    "print(\"Accuracy:\",(len(test_labels) - len(errors))/len(test_labels)*100,\"%\")\n",
    "\n",
    "print(metrics.classification_report(predictions, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4-fold cross-validation accuracy: %67.8 (+/-0.6)\n"
     ]
    }
   ],
   "source": [
    "crossvalidate(rf,features,labels,CV=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0533, 'illness'),\n",
       " (0.0531, 'DET'),\n",
       " (0.0529, 'ADJ'),\n",
       " (0.0509, 'ADP'),\n",
       " (0.0505, 'NUM'),\n",
       " (0.0504, 'label'),\n",
       " (0.0501, 'PRON'),\n",
       " (0.0498, 'AUX'),\n",
       " (0.0494, 'postID'),\n",
       " (0.0494, 'CCONJ'),\n",
       " (0.0493, 'VERB'),\n",
       " (0.0488, 'Ipp'),\n",
       " (0.0485, 'SCONJ'),\n",
       " (0.0478, 'INTJ'),\n",
       " (0.0477, 'wpp'),\n",
       " (0.0462, 'source'),\n",
       " (0.0458, 'X'),\n",
       " (0.0448, 'PUNCT'),\n",
       " (0.0391, 'NOUN'),\n",
       " (0.0329, 'ADV'),\n",
       " (0.0206, 'PROPN'),\n",
       " (0.0184, 'PART')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), d.columns), \n",
    "             reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-ec3381ba7bf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_predict\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# y_pred = cross_val_predict(rf, test_features, test_labels, cv=4)\n",
    "# conf_mat = confusion_matrix(test_labels, y_pred)\n",
    "# conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## equal classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM  \n",
    "https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM; 70/30 split; min 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob Rosen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mask_word20 = (d[\"wpp\"] >= 20)\n",
    "d_word20 = d[mask_word20]\n",
    "d_word20_data = d_word20[d.columns[5:]].as_matrix()\n",
    "\n",
    "features = d_word20_data\n",
    "labels = np.array(d_word20[\"label\"])\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel = linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(train_features, train_labels) \n",
    "svm_predictions = svm_model_linear.predict(test_features) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(test_features, test_labels) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(test_labels, svm_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.376269621421976\n",
      "[[396   7   0   4  25]\n",
      " [245  25  12  13 132]\n",
      " [146  14  20   8 243]\n",
      " [212  19   4  24 206]\n",
      " [ 44   4  13   0 350]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel = rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob Rosen\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3785228377065112\n",
      "[[   0    0    0  265    2]\n",
      " [   0    0    0  314    6]\n",
      " [   0    0    6  878   33]\n",
      " [   0    0    2 1466   45]\n",
      " [   0    0    5 1008   86]]\n"
     ]
    }
   ],
   "source": [
    "svm_model_linear = SVC(kernel = 'rbf', C = 1).fit(train_features, train_labels) \n",
    "svm_predictions = svm_model_linear.predict(test_features) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(test_features, test_labels) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(test_labels, svm_predictions) \n",
    "print(accuracy)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel = poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3850415512465374\n",
      "[[360 199 130 178  37]\n",
      " [ 27  45  18  28   3]\n",
      " [  0  10  37  10  20]\n",
      " [ 20  45  26  60  19]\n",
      " [ 25 128 220 189 332]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm_model_linear = SVC(kernel = 'poly', C = 1,gamma=\"scale\").fit(train_features, train_labels) \n",
    "svm_predictions = svm_model_linear.predict(test_features) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(test_features, test_labels) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(svm_predictions,test_labels) \n",
    "print(accuracy)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
